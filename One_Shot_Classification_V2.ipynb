{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "One-Shot Classification.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Naren-Jegan/Deep-Learning-Keras/blob/master/One_Shot_Classification_V2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "B5KR1KHjuk6N",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# One Shot Learning on Omniglot Dataset\n",
        "\n",
        "The [Omniglot](https://github.com/brendenlake/omniglot) dataset contains 1623 different handwritten characters from 50 different alphabets.\n",
        "Each of the 1623 characters was drawn online via Amazon's Mechanical Turk by 20 different people.\n",
        "This dataset has been the baseline for any one-shot learning algorithm.\n",
        "\n",
        "\n",
        "Some of the machine learning algorithms used for learning this dataset over the years are listed below in order of accuracy:\n",
        "*  Hierarchical Bayesian Program Learning - 95.2%\n",
        "*  Convolutional Siamese Net                        - 92.0%\n",
        "*  Affine model                                                  - 81.8%\n",
        "*  Hierarchical Deep                                         - 65.2%\n",
        "*  Deep Boltzmann Machine                           - 62.0%\n",
        "*  Siamese Neural Net                                     - 58.3%\n",
        "*  Simple Stroke                                                - 35.2%\n",
        "*  1-Nearest Neighbor                                      - 21.7%\n",
        "\n",
        "\n",
        "This notebook implements a [Convolutional Siamese Neural Network](https://https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf) using a background set of 30 alphabets for training and evaluate on set of 20 alphabets."
      ]
    },
    {
      "metadata": {
        "id": "099uR_fO1rqt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# How is the data?\n",
        "\n",
        "The Omniglot data set contains 50 alphabets total. It is split into a background set of 30 alphabets and an evaluation set of 20 alphabets.\n",
        "\n",
        "To compare with the results in the paper [Siamese Neural Networks for One-shot Image Recognition](https://www.cs.cmu.edu/~rsalakhu/papers/oneshot1.pdf), only the background set should be used to learn general knowledge about characters (e.g., hyperparameter inference or feature learning). One-shot learning results are reported using alphabets from the evaluation set.\n",
        "\n",
        "# Where is the data stored?\n",
        "\n",
        "The actual zipped Omniglot dataset, extracted and processed data (Pickled data) are stored in my google drive folder named \"One-Shot Classification\". To mount the drive, we use 2 packages, namely:\n",
        "\n",
        "\n",
        "1.   google.colab.auth - for authentication to drive\n",
        "2.   google.colab.drive - for mounting from drive\n",
        "\n",
        "# Hyper Parameter Optimisation - HyperOpt\n",
        "\n",
        "\n",
        "Hyperopt is a Python library for serial and parallel optimization over awkward search spaces, which may include real-valued, discrete, and conditional dimensions.\n",
        "\n",
        "[Github Link](http://github.com/hyperopt/hyperopt)\n",
        "\n",
        "In thiis notebook we use hyperopt trials to find the best hyper-parameters for the One-Shot Classification model. Hyperopt uses Bayesian optimization techniques to search. Tree-structured Parzen Estimator - TPE is used in this implementation.\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "7JehlDIHLpYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0117fcb4-b244-41d1-cd82-fe77aa537c25"
      },
      "cell_type": "code",
      "source": [
        "!pip install -q hyperopt\n",
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "B4ZNT7RO6C91",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Imported Normal Libraries\n",
        "\n",
        "\n",
        "*   matplotlib.pyplot - To plot images\n",
        "*   numpy - Tensor manipulation\n",
        "*   os - File system manipulation after mounting from Drive\n",
        "*   PIL.Image - To convert image files into numpy arrays\n",
        "*   pickle - To store objects are files (mainly numpy arrays in this implementation)\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "DqpZVzsXLVEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy.random as rnd\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Dkg4XY-g7hn3",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tensorflow, Keras and Hyperopt Imports\n",
        "*   **Keras**\n",
        "   *  models - To create, load and save models\n",
        "   *  layers - To create different types of layers\n",
        "   *  preprocessing.image - To generate image transformations\n",
        "   *  backend - Utilities to modelfy Keras objects\n",
        "   *  optimizers - To create optimizers\n",
        "   *  regularizers - To create regularizers\n",
        "   *  initializers - To create kernel and bias initializers\n",
        "   *  legacy - To refer keras source\n",
        "*  **Tensorflow**\n",
        "   *  logging - To avoid unnecessary prints\n",
        "   *  test - To check if GPU is available\n",
        "*  **Hyperopt**\n",
        "   *  hp - All randomization functions\n",
        "   *  fmin - Optimization function to minimize objective\n",
        "   *  tpe - Tree-structured Parzen Estimator\n",
        "   *  Trails - Object to hold each run information\n",
        "   *  STATUS_OK - Flag to proceed to next run"
      ]
    },
    {
      "metadata": {
        "id": "NKI63h3_VtZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "8472448a-c6e6-4e2f-981c-0fe01205a321"
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.models import Model, Sequential\n",
        "from tensorflow.python.keras.layers import InputLayer, Input, Lambda\n",
        "from tensorflow.python.keras.layers import Reshape, MaxPooling2D, BatchNormalization\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.python.keras.models import load_model\n",
        "from tensorflow.python.keras import backend as K\n",
        "from tensorflow.python.keras.optimizers import Optimizer\n",
        "from tensorflow.python.keras.regularizers import l2\n",
        "from tensorflow.python.keras.initializers import RandomNormal\n",
        "from tensorflow import test, logging\n",
        "from hyperopt import hp, fmin, tpe, STATUS_OK, Trials\n",
        "from keras.legacy import interfaces\n",
        "\n",
        "logging.set_verbosity(tf.logging.ERROR)\n",
        "test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "CDpwc_CmVtZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "40769be4-a4ff-4725-9f65-83b799a3a613"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.12.0-rc1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "M3n00DxT_nZ5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# File System Structure\n",
        "\n",
        "One-Shot Classification\n",
        "\n",
        "\n",
        "* Background\n",
        "  * Alphabet_of_the_Magi\n",
        "    *  character01\n",
        "      *  0709_01.png\n",
        "      *  0709_02.png\n",
        "      *  .\n",
        "      *  .\n",
        "      *  .\n",
        "    *  character02\n",
        "    *  .\n",
        "    *  .\n",
        "    *  .\n",
        "  * Anglo-Saxon_Futhorc\n",
        "  * .\n",
        "  * .\n",
        "  * .\n",
        "\n",
        "* Evaluation\n",
        "  * Angelic\n",
        "    *  character01\n",
        "      *  0965_01.png\n",
        "      *  0965_02.png\n",
        "      *  .\n",
        "      *  .\n",
        "      *  .\n",
        "    *  character02\n",
        "    *  .\n",
        "    *  .\n",
        "    *  .\n",
        "  * Atemayar_Qelisayer\n",
        "  * .\n",
        "  * .\n",
        "  * .\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "EVJ_ESVmxdDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#path to main folder\n",
        "one_shot_path = os.path.join(\"drive\", \"My Drive\", \"Colab Notebooks\", \"One-Shot Classification\")\n",
        "\n",
        "#path to background and evaluation data\n",
        "background_path = os.path.join(one_shot_path, \"background\")\n",
        "evaluation_path = os.path.join(one_shot_path, \"evaluation\")\n",
        "\n",
        "#path to final model\n",
        "recognition_model_path = os.path.join(one_shot_path, \"recognition_model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MaMJpKcSJs33",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Preprocessing and Pickling\n",
        "\n",
        "Both the training and test data are converted in a 4 dimensional array of the following form,\n",
        "\n",
        ">(Character_id, Writer_id, Pixel_X, Pixel_Y)\n",
        "\n",
        "> where,\n",
        "\n",
        "\n",
        "*   Character_id - number given in the filename as **number**_writer.png\n",
        "*   Writer_id - writer given in the filename as number_**writer**.png\n",
        "*   Pixel_X - X coordinate of pixel value\n",
        "*   Pixel_Y - Y coordinate of pixel value\n",
        "\n",
        "Along with this data, store a mapping contating the alphabets and it's starting character_id number\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "xeeysjWca_w4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "##creating training set\n",
        "train_data = np.ndarray(shape=(964, 20, 105, 105))\n",
        "train_alphabets = dict()\n",
        "\n",
        "#Preprocessing\n",
        "#for alphabet in os.listdir(background_path):\n",
        "#  alphabet_path = os.path.join(background_path, alphabet)\n",
        "#  for character in os.listdir(alphabet_path):\n",
        "#    character_path = os.path.join(alphabet_path, character)\n",
        "#    for image in os.listdir(character_path):\n",
        "#      index = int(image[0:4]) - 1\n",
        "#      writer = int(image[5:7]) - 1\n",
        "#      train_data[index][writer] = np.array(Image.open(os.path.join(character_path, image)))\n",
        "#      train_alphabets[alphabet] = index if alphabet not in train_alphabets or train_alphabets[alphabet] > index else train_alphabets[alphabet]\n",
        "\n",
        "#with open(os.path.join(\"train.pickle\"), 'wb') as f:\n",
        "#  pickle.dump([train_data, train_alphabets], f, protocol=2)\n",
        "\n",
        "##creating test set\n",
        "test_data = np.ndarray(shape=(659, 20, 105, 105))\n",
        "test_alphabets = dict()\n",
        "\n",
        "#Preprocessing\n",
        "#for alphabet in os.listdir(evaluation_path):\n",
        "#  alphabet_path = os.path.join(evaluation_path, alphabet)\n",
        "#  for character in os.listdir(alphabet_path):\n",
        "#    character_path = os.path.join(alphabet_path, character)\n",
        "#    for image in os.listdir(character_path):\n",
        "#      index = int(image[0:4]) - 965\n",
        "#      writer = int(image[5:7]) - 1\n",
        "#      test_data[index][writer] = np.array(Image.open(os.path.join(character_path, image)))\n",
        "#      test_alphabets[alphabet] = index if alphabet not in test_alphabets or test_alphabets[alphabet] > index else test_alphabets[alphabet]\n",
        "\n",
        "#with open(os.path.join(\"test.pickle\"), 'wb') as f:\n",
        "#  pickle.dump([test_data, test_alphabets], f, protocol=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JOZwcwdoLTXW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Loading Preprocessed training and test data (train.pickle and test.pickle)"
      ]
    },
    {
      "metadata": {
        "id": "4LVoh_EoogUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "with open(os.path.join(one_shot_path, \"train.pickle\"), 'rb') as f:\n",
        "  train_data, train_alphabets = pickle.load(f, encoding='latin1')\n",
        "  \n",
        "with open(os.path.join(one_shot_path, \"test.pickle\"), 'rb') as f:\n",
        "  test_data, test_alphabets = pickle.load(f, encoding='latin1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDGhQ-1y3DzM",
        "colab_type": "code",
        "colab": {},
        "cellView": "both"
      },
      "cell_type": "code",
      "source": [
        "batch_size = 128\n",
        "image_size = 105"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YDadpHK4LmN4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Image Augmentation Ranges\n",
        "During data generation, images are transformed to provide a more robust training. The parameters for the transformations are defined as follows:\n",
        "\n",
        "*   Rotation Range - maximum degrees upto which image can be rotated clockwise and anti-clockwise\n",
        "*   Width Shift Range - maximum number of pixels upto which image can be shifted to the left or right\n",
        "*   Height Shift Range - maximum number of pixels upto which image can be shifted to the up or down\n",
        "*   Shear Range - maximum degree of shearing allowed\n",
        "*   Zoom Range\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "uUNq4VOt1VBS",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Data Augmentation\n",
        "rotation_range = 10 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "width_shift_range = 2 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "height_shift_range = 2 #@param {type:\"slider\", min:0, max:10, step:0.1}\n",
        "shear_range = 0.3 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "zoom_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.01}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "y8Qg2MGUOa5v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Batch Generation\n",
        "\n",
        "\n",
        "*   Create X1, X2 which will contain batch_size number of images paired against one other for comparison \n",
        "*   Create Y which will contain the results of comparison for the whole batch\n",
        "*   Each alphabet should get equal representation in the training\n",
        "  *  s_alphabets -> alphabet's starting character_ids in sorted order\n",
        "  *  times -> number of times each alphabet can be represented in a single batch equally for both same and different pairs\n",
        "  *  reminder -> number of times alphabets have to be picked at random cause batch size is not a multiple of the number of alphabets\n",
        "*  For each alphabet chosen, create same (writer) and different (character) pairs\n",
        "  *  w_range -> writers to chose from\n",
        "  *  c_range -> characters to choose from\n",
        "  *  transform_image -> image augmentation function\n",
        "  \n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "MhqXSHZ3hG9u",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "datagen = ImageDataGenerator()\n",
        "\n",
        "def transform_image(image):\n",
        "  return datagen.apply_transform(image.reshape((image_size, image_size, 1)), \n",
        "                                 transform_parameters = \n",
        "                       {'theta': rnd.uniform(-rotation_range, rotation_range),\n",
        "                        'tx'   : rnd.uniform(-width_shift_range, width_shift_range),\n",
        "                        'ty'   : rnd.uniform(-height_shift_range, height_shift_range),\n",
        "                        'shear': rnd.uniform(-shear_range, shear_range),\n",
        "                        'zx'   : rnd.uniform(-zoom_range, zoom_range),\n",
        "                        'zy'   : rnd.uniform(-zoom_range, zoom_range)\n",
        "                       })\n",
        "\n",
        "#generate image pairs [x1, x2] with target y = 1/0 representing same/different\n",
        "def datagen_flow(datagen):\n",
        "    while True:\n",
        "      X1 = np.ndarray(shape=(batch_size, image_size, image_size, 1))\n",
        "      X2 = np.ndarray(shape=(batch_size, image_size, image_size, 1))\n",
        "      Y = np.ndarray(shape=(batch_size,))\n",
        "      \n",
        "      s_alphabets = sorted(train_alphabets.values())\n",
        "      a_indices = list(range(len(s_alphabets)))\n",
        "      times = batch_size//(2*len(a_indices))\n",
        "      remainder = (batch_size//2)%len(a_indices)\n",
        "      \n",
        "      aindices = a_indices*times + list(rnd.choice(a_indices, remainder))\n",
        "      rnd.shuffle(aindices)\n",
        "      \n",
        "      w_range = list(range(20))\n",
        "      \n",
        "      i = 0   \n",
        "      for a in aindices:\n",
        "        end_index = (len(train_data) if a+1 == len(s_alphabets) else s_alphabets[a+1])\n",
        "        c_range = list(range(s_alphabets[a], end_index))\n",
        "        \n",
        "        writers = rnd.choice(w_range, 2)\n",
        "        same = rnd.choice(c_range)\n",
        "        X1[2*i] = transform_image(train_data[same, writers[0]])\n",
        "        X2[2*i] = transform_image(train_data[same, writers[1]])\n",
        "        Y[2*i] = 1.0\n",
        "        \n",
        "        writers = rnd.choice(w_range, 2)\n",
        "        diff = rnd.choice(c_range, 2)\n",
        "        X1[2*i + 1] = transform_image(train_data[diff[0], writers[0]])\n",
        "        X2[2*i + 1] = transform_image(train_data[diff[1], writers[1]])\n",
        "        Y[2*i + 1] = 0.0\n",
        "        \n",
        "        i += 1\n",
        "        \n",
        "      yield [X1, X2], Y\n",
        "\n",
        "train_generator = datagen_flow(datagen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PqLa_1Ct1OsS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "class Modified_SGD(Optimizer):\n",
        "    \"\"\" Modified Stochastic gradient descent optimizer.\n",
        "    Reorganized SGD to allow layer-wise momentum and learning-rate\n",
        "    Includes support for momentum,\n",
        "    learning rate decay, and Nesterov momentum.\n",
        "    Includes the possibility to add multipliers to different\n",
        "    learning rates in each layer.\n",
        "    # Arguments\n",
        "        lr: float >= 0. Learning rate.\n",
        "        momentum: float >= 0. Parameter updates momentum.\n",
        "        decay: float >= 0. Learning rate decay over each update.\n",
        "        nesterov: boolean. Whether to apply Nesterov momentum.\n",
        "        lr_values: dictionary with learning rate for a specific layer\n",
        "        for example:\n",
        "            # Setting the Learning rate multipliers\n",
        "            lr_values = {}\n",
        "            lr_values['conv1']=1\n",
        "        momentum_values: dictionary with momentum for a specific layer\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lr=1, momentum=0.5, decay=0., n_epochs=200,\n",
        "                 nesterov=False, lr_values=None, momentum_values=None, **kwargs):\n",
        "        super(Modified_SGD, self).__init__(**kwargs)\n",
        "        with K.name_scope(self.__class__.__name__):\n",
        "            self.iterations = K.variable(0, dtype='int64', name='iterations')\n",
        "            self.lr = K.variable(lr, name='lr')\n",
        "            self.momentum = K.variable(momentum, name='momentum')\n",
        "            self.decay = K.variable(decay, name='decay')\n",
        "        self.initial_decay = decay\n",
        "        self.nesterov = nesterov\n",
        "        self.lr_values = lr_values\n",
        "        self.momentum_values = momentum_values\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "    @interfaces.legacy_get_updates_support\n",
        "    def get_updates(self, loss, params):\n",
        "        grads = self.get_gradients(loss, params)\n",
        "        self.updates = [K.update_add(self.iterations, 1)]\n",
        "\n",
        "        lr = self.lr\n",
        "        if self.initial_decay > 0:\n",
        "            lr *= (1. / (1. + self.decay * K.cast(self.iterations,\n",
        "                                                  K.dtype(self.decay))))\n",
        "        \n",
        "        \n",
        "        # momentum\n",
        "        shapes = [K.int_shape(p) for p in params]\n",
        "        moments = [K.zeros(shape) for shape in shapes]\n",
        "        self.weights = [self.iterations] + moments\n",
        "        for p, g, m in zip(params, grads, moments):\n",
        "\n",
        "            if self.lr_values != None:\n",
        "                if p.name in self.lr_values:\n",
        "                    new_lr = lr * self.lr_values[p.name]\n",
        "                else:\n",
        "                    new_lr = lr\n",
        "            else:\n",
        "                new_lr = lr\n",
        "\n",
        "            if self.momentum_values != None:\n",
        "                if p.name in self.momentum_values:\n",
        "                    new_momentum = ((self.momentum_values[p.name] - self.momentum)/self.n_epochs)*self.iterations + self.momentum  \n",
        "                else:\n",
        "                    new_momentum = self.momentum\n",
        "            else:\n",
        "                new_momentum = self.momentum\n",
        "            \n",
        "            # velocity\n",
        "            v = new_momentum * m - new_lr * g  \n",
        "            self.updates.append(K.update(m, v))\n",
        "\n",
        "            if self.nesterov:\n",
        "                new_p = p + new_momentum * v - new_lr * g\n",
        "            else:\n",
        "                new_p = p + v\n",
        "\n",
        "            # Apply constraints.\n",
        "            if getattr(p, 'constraint', None) is not None:\n",
        "                new_p = p.constraint(new_p)\n",
        "\n",
        "            self.updates.append(K.update(p, new_p))\n",
        "        return self.updates\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'lr': float(K.get_value(self.lr)),\n",
        "                  'momentum': float(K.get_value(self.momentum)),\n",
        "                  'decay': float(K.get_value(self.decay)),\n",
        "                  'nesterov': self.nesterov,\n",
        "                  'lr_values': self.lr_values,\n",
        "                  'momentum_values': self.momentum_values}\n",
        "        base_config = super(Modified_SGD, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qihLXdaHNSFj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "w_init = RandomNormal(mean=0.0, stddev=1e-2)\n",
        "b_init = RandomNormal(mean=0.5, stddev=1e-2)\n",
        "input_shape=(image_size, image_size, 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vHlxoQHV6oVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def validate(model, test = False, show = False):\n",
        "  N = 20\n",
        "  \n",
        "  st_alphabets = sorted(test_alphabets.values())\n",
        "  max_index = len(test_data) if test else st_alphabets[10]\n",
        "  st_alphabets = st_alphabets[10:20] if test else st_alphabets[0:10]\n",
        "  correct = 0\n",
        "  for i in range(len(st_alphabets)):\n",
        "    end_index = max_index if i+1 == len(st_alphabets) else st_alphabets[i+1] \n",
        "    c_range = list(range(st_alphabets[i],end_index))\n",
        "\n",
        "    for j in range(2):\n",
        "      c_list = rnd.choice(c_range, N)\n",
        "      w_list = rnd.choice(range(20), 2)\n",
        "\n",
        "      for c_i in range(N):\n",
        "        image = test_data[c_list[c_i]][w_list[0]]\n",
        "\n",
        "        X1 = np.array([image]*N).reshape((N, image_size, image_size, 1))\n",
        "        X2 = np.array(test_data[c_list][w_list[1]]).reshape((N, image_size, image_size, 1))\n",
        "        if show and c_i == 2 and i == 3:\n",
        "          plt.imshow(image)\n",
        "          plt.show()\n",
        "          for m in range(N):\n",
        "            plt.imshow(test_data[c_list[m]][w_list[1]])\n",
        "            plt.show()\n",
        "\n",
        "\n",
        "        targets = np.zeros((N,))\n",
        "        targets[c_i] = 1\n",
        "        predictions = model.predict([X1, X2])\n",
        "\n",
        "        if show and c_i == 2 and i == 3:\n",
        "          print(targets)\n",
        "          print(predictions)\n",
        "          show = False\n",
        "          \n",
        "        if(np.argmax(predictions) == np.argmax(targets)):\n",
        "          correct += 1\n",
        "  return (100*correct/(N*10*2))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-kEFic269Ll",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#CallBacks\n",
        "from tensorflow.python.keras.callbacks import LearningRateScheduler\n",
        "\n",
        "lr_scheduler = LearningRateScheduler(lambda epoch, lr: 0.99*lr)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SzwK0wtPVtZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def One_Shot_Model(params):\n",
        "  \n",
        "  print(params)\n",
        "  \n",
        "  lr_values = dict()\n",
        "  lr_values['layer_conv1'] = params['l_c1']\n",
        "  lr_values['layer_conv2'] = params['l_c2']\n",
        "  lr_values['layer_conv3'] = params['l_c3']\n",
        "  lr_values['layer_conv4'] = params['l_c4']\n",
        "  lr_values['layer_dense1'] = params['l_d1']\n",
        "  \n",
        "  momentum_values = dict()\n",
        "  momentum_values['layer_conv1'] = params['m_c1']\n",
        "  momentum_values['layer_conv2'] = params['m_c2']\n",
        "  momentum_values['layer_conv3'] = params['m_c3']\n",
        "  momentum_values['layer_conv4'] = params['m_c4']\n",
        "  momentum_values['layer_dense1'] = params['m_d1']\n",
        "  \n",
        "  reg_values = dict()\n",
        "  reg_values['layer_conv1'] = params['r_c1']\n",
        "  reg_values['layer_conv2'] = params['r_c2']\n",
        "  reg_values['layer_conv3'] = params['r_c3']\n",
        "  reg_values['layer_conv4'] = params['r_c4']\n",
        "  reg_values['layer_dense1'] = params['r_d1']\n",
        "  \n",
        "  left_input = Input(input_shape)\n",
        "  right_input = Input(input_shape)\n",
        "\n",
        "  # Start construction of the Keras Sequential model.\n",
        "  convnet = Sequential()\n",
        "\n",
        "  # First convolutional layer with activation, batchnorm and max-pooling.\n",
        "  convnet.add(Conv2D(kernel_size=10, strides=1, filters=64, padding='valid',\n",
        "                     input_shape=input_shape, bias_initializer=b_init,\n",
        "                     activation='relu',\n",
        "                     name='layer_conv1', kernel_regularizer=l2(reg_values['layer_conv1'])))\n",
        "  convnet.add(BatchNormalization(axis = 3, name = 'bn1'))\n",
        "  convnet.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling1\"))\n",
        "\n",
        "  # Second convolutional layer with activation, batchnorm and max-pooling.\n",
        "  convnet.add(Conv2D(kernel_size=7, strides=1, filters=128, padding='valid',\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                    activation='relu', \n",
        "                    name='layer_conv2', kernel_regularizer=l2(reg_values['layer_conv2'])))\n",
        "  convnet.add(BatchNormalization(axis = 3, name = 'bn2'))\n",
        "  convnet.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling2\"))\n",
        "\n",
        "  # Third convolutional layer with activation, batchnorm and max-pooling.\n",
        "  convnet.add(Conv2D(kernel_size=4, strides=1, filters=128, padding='valid',\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                    activation='relu', \n",
        "                    name='layer_conv3', kernel_regularizer=l2(reg_values['layer_conv3'])))\n",
        "  convnet.add(BatchNormalization(axis = 3, name = 'bn3'))\n",
        "  convnet.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling3\"))\n",
        "\n",
        "  # Fourth convolutional layer with activation, batchnorm and max-pooling.\n",
        "  convnet.add(Conv2D(kernel_size=4, strides=1, filters=256, padding='valid',\n",
        "                    kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                    activation='relu', \n",
        "                    name='layer_conv4', kernel_regularizer=l2(reg_values['layer_conv4'])))\n",
        "  convnet.add(BatchNormalization(axis = 3, name = 'bn4'))\n",
        "  convnet.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling4\"))\n",
        "\n",
        "  # Flatten the 4-rank output of the convolutional layers\n",
        "  # to 2-rank that can be input to a fully-connected / dense layer.\n",
        "  convnet.add(Flatten())\n",
        "\n",
        "\n",
        "  # First fully-connected / dense layer with activation.\n",
        "  convnet.add(Dense(4096, activation='sigmoid',\n",
        "                   kernel_initializer=w_init, bias_initializer=b_init,\n",
        "                   name = \"layer_dense1\", kernel_regularizer=l2(reg_values['layer_dense1'])))\n",
        "  convnet.add(BatchNormalization(axis = 1, name = 'bn5'))\n",
        "\n",
        "  #call the convnet Sequential model on each of the input tensors so params will be shared\n",
        "  encoded_l = convnet(left_input)\n",
        "  encoded_r = convnet(right_input)\n",
        "\n",
        "  #layer to merge two encoded inputs with the l1 distance between them\n",
        "  L1_layer = Lambda(lambda tensors:K.abs(tensors[0] - tensors[1]))\n",
        "\n",
        "  #call this layer on list of two input tensors.\n",
        "  L1_distance = L1_layer([encoded_l, encoded_r])\n",
        "\n",
        "  prediction = Dense(1,activation='sigmoid',bias_initializer=b_init)(L1_distance)\n",
        "  \n",
        "  model = Model(inputs=[left_input,right_input],outputs=prediction)\n",
        "  \n",
        "  optimizer = Modified_SGD(lr=1, lr_values=lr_values, momentum_values=momentum_values, momentum=0.5, n_epochs=params['epochs'])\n",
        "  \n",
        "  model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "  \n",
        "  model.fit_generator(\n",
        "      train_generator,\n",
        "      steps_per_epoch=params['steps_per_epoch'],\n",
        "      epochs=params['epochs'],\n",
        "      callbacks=[lr_scheduler],\n",
        "      verbose=False\n",
        "  )\n",
        "  val_acc = validate(model)\n",
        "  print('Validation accuracy:', val_acc)\n",
        "  return {'loss': -val_acc, 'status': STATUS_OK, 'model': model}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bn6INMNmv0zk",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "trials_path = os.path.join(one_shot_path, 'trials.hyperopt')\n",
        "trials=Trials()\n",
        "\n",
        "#with open(trials_path, 'wb') as f:\n",
        "#  pickle.dump(trials, f, -1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MvFgcL2q_ICr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "space = {\n",
        "    'l_c1' : 10 ** hp.uniform('l_c1', -4, -1),\n",
        "    'l_c2' : 10 ** hp.uniform('l_c2', -4, -1),\n",
        "    'l_c3' : 10 ** hp.uniform('l_c3', -4, -1),\n",
        "    'l_c4' : 10 ** hp.uniform('l_c4', -4, -1),\n",
        "    'l_d1' : 10 ** hp.uniform('l_d1', -4, -1),\n",
        "    'm_c1' : hp.uniform('m_c1', 0.5, 1),\n",
        "    'm_c2' : hp.uniform('m_c2', 0.5, 1),\n",
        "    'm_c3' : hp.uniform('m_c3', 0.5, 1),\n",
        "    'm_c4' : hp.uniform('m_c4', 0.5, 1),\n",
        "    'm_d1' : hp.uniform('m_d1', 0.5, 1),\n",
        "    'r_c1' : hp.uniform('r_c1', 0, 0.1),\n",
        "    'r_c2' : hp.uniform('r_c2', 0, 0.1),\n",
        "    'r_c3' : hp.uniform('r_c3', 0, 0.1),\n",
        "    'r_c4' : hp.uniform('r_c4', 0, 0.1),\n",
        "    'r_d1' : hp.uniform('r_d1', 0, 0.1),\n",
        "    'epochs' : hp.choice('epochs', [100, 150, 200]),\n",
        "    'steps_per_epoch' : hp.choice('steps_per_epoch', [25, 50, 75, 100])\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KJ8SwSLURKNY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def remove_models(trials):\n",
        "    for trial in trials.trials:\n",
        "      if 'result' in trial.keys() and 'model' in trial['result'].keys():\n",
        "          trial['result'].pop('model', None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOrQ3XKbVtZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "c1ea7d70-dc81-449a-fc7c-f709a263efbc"
      },
      "cell_type": "code",
      "source": [
        "with open(trials_path, 'rb') as f:\n",
        "    trials = pickle.load(f, encoding='latin1')\n",
        "print(len(trials))\n",
        "while(len(trials) < 100): \n",
        "\n",
        "  best = fmin(One_Shot_Model, space, algo=tpe.suggest, trials=trials, max_evals=len(trials) + 1)\n",
        " \n",
        "  remove_models(trials)\n",
        "\n",
        "  with open(trials_path, 'wb') as f:\n",
        "    pickle.dump(trials, f, -1)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "65\n",
            "{'epochs': 150, 'l_c1': 0.00022182594742756577, 'l_c2': 0.0004904026832012446, 'l_c3': 0.007839308715903747, 'l_c4': 0.022107838757264534, 'l_d1': 0.020626535159663874, 'm_c1': 0.6144268251719842, 'm_c2': 0.8646820243068004, 'm_c3': 0.9997328893435087, 'm_c4': 0.6375577414269807, 'm_d1': 0.9724783354046371, 'r_c1': 0.025180002643174403, 'r_c2': 0.0823218921153721, 'r_c3': 0.0916695613434409, 'r_c4': 0.08897642460237798, 'r_d1': 0.09429529602370305, 'steps_per_epoch': 100}\n",
            "Validation accuracy: 6.25\n",
            "{'epochs': 150, 'l_c1': 0.0001393145233887026, 'l_c2': 0.00022685560413472777, 'l_c3': 0.04161486273820106, 'l_c4': 0.07170039857816095, 'l_d1': 0.005349902801599477, 'm_c1': 0.5794488016308013, 'm_c2': 0.9506472180310264, 'm_c3': 0.949249760761865, 'm_c4': 0.7189814867329805, 'm_d1': 0.8904555011373942, 'r_c1': 0.017795219664701663, 'r_c2': 0.0945586625964642, 'r_c3': 0.08081808712467228, 'r_c4': 0.09695660159451062, 'r_d1': 0.05477026455413756, 'steps_per_epoch': 100}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xcyM9a8YwdA1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "best_model_path = os.path.join(one_shot_path, 'One_Shot_Model.h5')\n",
        "print(\"Best performing model chosen hyper-parameters:\")\n",
        "print(trials.best_trial)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}