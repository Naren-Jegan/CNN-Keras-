{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Naren-Jegan/Deep-Learning-Keras/blob/master/Flower_Classifier_V2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "7JehlDIHLpYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "dc21422e-572a-4369-dd9a-1aa18e266ec9"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DqpZVzsXLVEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from PIL import Image, ImageFilter, ImageOps, ImageMath\n",
        "import random\n",
        "import pickle\n",
        "from time import sleep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKI63h3_VtZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "aef045a1-a463-4c38-bf2f-6e53dea11b56"
      },
      "cell_type": "code",
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import InputLayer, Input\n",
        "from tensorflow.python.keras.layers import Reshape, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import test\n",
        "test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "CDpwc_CmVtZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1badd1af-1910-4574-9581-43bbe92c4acf"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "EVJ_ESVmxdDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flowerspath = os.path.join(\"drive\", \"My Drive\", \"Colab Notebooks\", \"flowers\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDGhQ-1y3DzM",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Inputs\n",
        "\n",
        "activation = 'relu' #@param ['relu', 'softplus', 'tanh', 'sigmoid'] {type:\"string\"}\n",
        "learning_rate = 1e-3 #@param {type:\"number\"}\n",
        "dropout = 0.54 #@param {type:\"slider\", min:0.0, max:0.9, step:0.01}\n",
        "n_epochs = 225 #@param {type:\"slider\", min:25, max:500, step:25}\n",
        "batch_size = 128 #@param {type:\"slider\", min:0, max:1024, step:16}\n",
        "num_classes = 5 #@param {type:\"slider\", min:2, max:100, step:1} \n",
        "\n",
        "batch_size = 1 if batch_size == 0 else batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUNq4VOt1VBS",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "cell_type": "code",
      "source": [
        "#@title Data Augmentation\n",
        "image_size = 128 #@param {type:\"slider\", min:32, max:512, step:32}\n",
        "\n",
        "rotation_range = 40 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "width_shift_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "height_shift_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "shear_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "zoom_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "horizontal_flip = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MhqXSHZ3hG9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "74a70267-04e6-4dae-f40e-ed4283435144"
      },
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=rotation_range,\n",
        "        width_shift_range=width_shift_range,\n",
        "        height_shift_range=height_shift_range,\n",
        "        rescale=1./255,\n",
        "        shear_range=shear_range,\n",
        "        zoom_range=zoom_range,\n",
        "        horizontal_flip=horizontal_flip)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        os.path.join(flowerspath, 'train'), # this is the target directory\n",
        "        target_size=(image_size, image_size),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use categorical_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        os.path.join(flowerspath, 'validation'),\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3423 images belonging to 5 classes.\n",
            "Found 900 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SzwK0wtPVtZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start construction of the Keras Sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(input_shape=(image_size, image_size, 3), kernel_size=3, strides=1, filters=16, padding='same',\n",
        "                 activation=activation, name='layer_conv11'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn11'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling1\"))\n",
        "\n",
        "# Second convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=32, padding='same',\n",
        "                 activation=activation, name='layer_conv21'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn21'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling2\"))\n",
        "\n",
        "# Third convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same',\n",
        "                 activation=activation, name='layer_conv31'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn31'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling3\"))\n",
        "\n",
        "# Flatten the 4-rank output of the convolutional layers\n",
        "# to 2-rank that can be input to a fully-connected / dense layer.\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "# First fully-connected / dense layer with activation.\n",
        "model.add(Dense(1024, activation=activation, name = \"dense_1\"))\n",
        "model.add(BatchNormalization(axis = 1, name = 'bn8'))\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "# Second fully-connected / dense layer with activation.\n",
        "model.add(Dense(1024, activation=activation, name = \"dense_2\"))\n",
        "model.add(BatchNormalization(axis = 1, name = 'bn9'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax', name = \"dense_3\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnG3DzENVtZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLtZLFDCVtZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOrQ3XKbVtZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7996
        },
        "outputId": "b716f5a2-001e-44d4-855a-454ab4d4add1"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch= sum([len(files) for r, d, files in os.walk(os.path.join(flowerspath, \"train\"))])//batch_size,\n",
        "                    epochs=n_epochs,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps= sum([len(files) for r, d, files in os.walk(os.path.join(flowerspath, \"validation\"))])//batch_size\n",
        "         )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/225\n",
            "26/26 [==============================] - 34s 1s/step - loss: 1.7579 - acc: 0.4283 - val_loss: 2.3238 - val_acc: 0.2299\n",
            "Epoch 2/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 1.3826 - acc: 0.5150 - val_loss: 9.1978 - val_acc: 0.1998\n",
            "Epoch 3/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 1.1925 - acc: 0.5514 - val_loss: 8.7026 - val_acc: 0.1998\n",
            "Epoch 4/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 1.0945 - acc: 0.5836 - val_loss: 9.6701 - val_acc: 0.1998\n",
            "Epoch 5/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 1.0335 - acc: 0.6022 - val_loss: 9.7433 - val_acc: 0.1998\n",
            "Epoch 6/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.9649 - acc: 0.6223 - val_loss: 10.5537 - val_acc: 0.1998\n",
            "Epoch 7/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.9378 - acc: 0.6360 - val_loss: 8.7545 - val_acc: 0.1998\n",
            "Epoch 8/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.9305 - acc: 0.6385 - val_loss: 7.5126 - val_acc: 0.1998\n",
            "Epoch 9/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.8868 - acc: 0.6604 - val_loss: 6.3986 - val_acc: 0.2020\n",
            "Epoch 10/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.8788 - acc: 0.6571 - val_loss: 5.6043 - val_acc: 0.2065\n",
            "Epoch 11/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.8346 - acc: 0.6793 - val_loss: 4.1552 - val_acc: 0.2288\n",
            "Epoch 12/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.8381 - acc: 0.6882 - val_loss: 2.2752 - val_acc: 0.2891\n",
            "Epoch 13/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.8056 - acc: 0.6811 - val_loss: 2.8907 - val_acc: 0.2902\n",
            "Epoch 14/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.8047 - acc: 0.6921 - val_loss: 2.2069 - val_acc: 0.3616\n",
            "Epoch 15/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.7786 - acc: 0.6988 - val_loss: 1.8115 - val_acc: 0.4308\n",
            "Epoch 16/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.7599 - acc: 0.7048 - val_loss: 1.6541 - val_acc: 0.4609\n",
            "Epoch 17/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.7681 - acc: 0.6896 - val_loss: 2.2287 - val_acc: 0.4342\n",
            "Epoch 18/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.7491 - acc: 0.7163 - val_loss: 1.8521 - val_acc: 0.4152\n",
            "Epoch 19/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.7179 - acc: 0.7200 - val_loss: 1.4586 - val_acc: 0.5357\n",
            "Epoch 20/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.7435 - acc: 0.7154 - val_loss: 1.3998 - val_acc: 0.5592\n",
            "Epoch 21/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.7165 - acc: 0.7190 - val_loss: 0.9330 - val_acc: 0.6763\n",
            "Epoch 22/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.7171 - acc: 0.7242 - val_loss: 0.9338 - val_acc: 0.6797\n",
            "Epoch 23/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.6673 - acc: 0.7394 - val_loss: 0.9155 - val_acc: 0.6696\n",
            "Epoch 24/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.6725 - acc: 0.7362 - val_loss: 0.8421 - val_acc: 0.6987\n",
            "Epoch 25/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.6802 - acc: 0.7419 - val_loss: 0.8951 - val_acc: 0.6908\n",
            "Epoch 26/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.6623 - acc: 0.7419 - val_loss: 0.9546 - val_acc: 0.6987\n",
            "Epoch 27/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.6507 - acc: 0.7432 - val_loss: 0.8139 - val_acc: 0.6931\n",
            "Epoch 28/225\n",
            "26/26 [==============================] - 26s 983ms/step - loss: 0.6402 - acc: 0.7505 - val_loss: 0.8396 - val_acc: 0.7054\n",
            "Epoch 29/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.6358 - acc: 0.7528 - val_loss: 0.7294 - val_acc: 0.7489\n",
            "Epoch 30/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.6510 - acc: 0.7482 - val_loss: 0.8193 - val_acc: 0.7143\n",
            "Epoch 31/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.6073 - acc: 0.7614 - val_loss: 0.7708 - val_acc: 0.7299\n",
            "Epoch 32/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.6168 - acc: 0.7600 - val_loss: 0.7805 - val_acc: 0.7176\n",
            "Epoch 33/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.6143 - acc: 0.7692 - val_loss: 0.9793 - val_acc: 0.6529\n",
            "Epoch 34/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5905 - acc: 0.7683 - val_loss: 0.9174 - val_acc: 0.6942\n",
            "Epoch 35/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.6067 - acc: 0.7698 - val_loss: 0.9003 - val_acc: 0.7020\n",
            "Epoch 36/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5997 - acc: 0.7653 - val_loss: 0.8357 - val_acc: 0.6998\n",
            "Epoch 37/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.5726 - acc: 0.7742 - val_loss: 0.7946 - val_acc: 0.7299\n",
            "Epoch 38/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.5869 - acc: 0.7718 - val_loss: 0.8865 - val_acc: 0.7154\n",
            "Epoch 39/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5871 - acc: 0.7677 - val_loss: 0.7437 - val_acc: 0.7511\n",
            "Epoch 40/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5551 - acc: 0.7828 - val_loss: 0.7458 - val_acc: 0.7556\n",
            "Epoch 41/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5665 - acc: 0.7713 - val_loss: 0.8265 - val_acc: 0.7355\n",
            "Epoch 42/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5505 - acc: 0.7932 - val_loss: 0.8863 - val_acc: 0.6998\n",
            "Epoch 43/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5363 - acc: 0.7943 - val_loss: 0.8491 - val_acc: 0.7199\n",
            "Epoch 44/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5300 - acc: 0.7849 - val_loss: 0.7066 - val_acc: 0.7567\n",
            "Epoch 45/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5247 - acc: 0.8025 - val_loss: 0.8972 - val_acc: 0.7154\n",
            "Epoch 46/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5260 - acc: 0.7996 - val_loss: 0.8042 - val_acc: 0.7299\n",
            "Epoch 47/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5082 - acc: 0.8126 - val_loss: 0.8769 - val_acc: 0.7121\n",
            "Epoch 48/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5265 - acc: 0.7955 - val_loss: 1.2964 - val_acc: 0.6261\n",
            "Epoch 49/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.5074 - acc: 0.8088 - val_loss: 0.9070 - val_acc: 0.6964\n",
            "Epoch 50/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5213 - acc: 0.7955 - val_loss: 0.8676 - val_acc: 0.7132\n",
            "Epoch 51/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5041 - acc: 0.8052 - val_loss: 0.8444 - val_acc: 0.7310\n",
            "Epoch 52/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.5159 - acc: 0.8041 - val_loss: 0.8484 - val_acc: 0.7210\n",
            "Epoch 53/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.5030 - acc: 0.8041 - val_loss: 0.8968 - val_acc: 0.7020\n",
            "Epoch 54/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4949 - acc: 0.8122 - val_loss: 0.8860 - val_acc: 0.7176\n",
            "Epoch 55/225\n",
            "26/26 [==============================] - 25s 979ms/step - loss: 0.4629 - acc: 0.8200 - val_loss: 0.8390 - val_acc: 0.7411\n",
            "Epoch 56/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4670 - acc: 0.8187 - val_loss: 0.8440 - val_acc: 0.7232\n",
            "Epoch 57/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4937 - acc: 0.8111 - val_loss: 0.9456 - val_acc: 0.7288\n",
            "Epoch 58/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4876 - acc: 0.8049 - val_loss: 0.8843 - val_acc: 0.7165\n",
            "Epoch 59/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.4867 - acc: 0.8149 - val_loss: 0.7989 - val_acc: 0.7388\n",
            "Epoch 60/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4563 - acc: 0.8266 - val_loss: 0.8561 - val_acc: 0.7143\n",
            "Epoch 61/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4415 - acc: 0.8308 - val_loss: 0.8800 - val_acc: 0.7188\n",
            "Epoch 62/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4973 - acc: 0.8173 - val_loss: 0.9560 - val_acc: 0.7154\n",
            "Epoch 63/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4676 - acc: 0.8172 - val_loss: 0.7592 - val_acc: 0.7455\n",
            "Epoch 64/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4560 - acc: 0.8270 - val_loss: 0.7985 - val_acc: 0.7545\n",
            "Epoch 65/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4650 - acc: 0.8264 - val_loss: 0.7929 - val_acc: 0.7478\n",
            "Epoch 66/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4502 - acc: 0.8254 - val_loss: 0.8967 - val_acc: 0.6953\n",
            "Epoch 67/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4303 - acc: 0.8347 - val_loss: 1.0661 - val_acc: 0.6964\n",
            "Epoch 68/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4304 - acc: 0.8438 - val_loss: 0.8552 - val_acc: 0.7366\n",
            "Epoch 69/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4298 - acc: 0.8364 - val_loss: 0.9779 - val_acc: 0.7176\n",
            "Epoch 70/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4387 - acc: 0.8311 - val_loss: 0.8480 - val_acc: 0.7254\n",
            "Epoch 71/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.4207 - acc: 0.8392 - val_loss: 0.7818 - val_acc: 0.7455\n",
            "Epoch 72/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4150 - acc: 0.8389 - val_loss: 0.8924 - val_acc: 0.7344\n",
            "Epoch 73/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4274 - acc: 0.8361 - val_loss: 0.8331 - val_acc: 0.7444\n",
            "Epoch 74/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4099 - acc: 0.8506 - val_loss: 0.9743 - val_acc: 0.6964\n",
            "Epoch 75/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.4127 - acc: 0.8399 - val_loss: 1.4277 - val_acc: 0.6406\n",
            "Epoch 76/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.4307 - acc: 0.8361 - val_loss: 0.9056 - val_acc: 0.7176\n",
            "Epoch 77/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.4119 - acc: 0.8380 - val_loss: 1.0303 - val_acc: 0.7199\n",
            "Epoch 78/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3938 - acc: 0.8504 - val_loss: 0.8243 - val_acc: 0.7366\n",
            "Epoch 79/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3872 - acc: 0.8526 - val_loss: 0.7403 - val_acc: 0.7667\n",
            "Epoch 80/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3959 - acc: 0.8470 - val_loss: 0.7159 - val_acc: 0.7913\n",
            "Epoch 81/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3810 - acc: 0.8505 - val_loss: 0.7938 - val_acc: 0.7533\n",
            "Epoch 82/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3952 - acc: 0.8567 - val_loss: 0.8100 - val_acc: 0.7600\n",
            "Epoch 83/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3887 - acc: 0.8532 - val_loss: 0.8190 - val_acc: 0.7478\n",
            "Epoch 84/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3692 - acc: 0.8634 - val_loss: 0.9239 - val_acc: 0.7500\n",
            "Epoch 85/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3878 - acc: 0.8526 - val_loss: 0.8678 - val_acc: 0.7500\n",
            "Epoch 86/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3561 - acc: 0.8630 - val_loss: 1.0019 - val_acc: 0.7065\n",
            "Epoch 87/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3720 - acc: 0.8599 - val_loss: 1.1311 - val_acc: 0.7042\n",
            "Epoch 88/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3514 - acc: 0.8618 - val_loss: 0.9113 - val_acc: 0.7210\n",
            "Epoch 89/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3898 - acc: 0.8515 - val_loss: 0.9937 - val_acc: 0.7288\n",
            "Epoch 90/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3932 - acc: 0.8522 - val_loss: 1.0897 - val_acc: 0.7054\n",
            "Epoch 91/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3575 - acc: 0.8627 - val_loss: 1.0097 - val_acc: 0.7366\n",
            "Epoch 92/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3767 - acc: 0.8613 - val_loss: 0.7758 - val_acc: 0.7734\n",
            "Epoch 93/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3448 - acc: 0.8702 - val_loss: 0.8427 - val_acc: 0.7533\n",
            "Epoch 94/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3613 - acc: 0.8654 - val_loss: 1.0004 - val_acc: 0.7176\n",
            "Epoch 95/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3457 - acc: 0.8659 - val_loss: 1.0138 - val_acc: 0.7076\n",
            "Epoch 96/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3511 - acc: 0.8660 - val_loss: 0.8146 - val_acc: 0.7433\n",
            "Epoch 97/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3361 - acc: 0.8750 - val_loss: 0.8621 - val_acc: 0.7545\n",
            "Epoch 98/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3304 - acc: 0.8795 - val_loss: 0.8593 - val_acc: 0.7478\n",
            "Epoch 99/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3613 - acc: 0.8679 - val_loss: 0.9185 - val_acc: 0.7444\n",
            "Epoch 100/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3421 - acc: 0.8752 - val_loss: 0.9001 - val_acc: 0.7400\n",
            "Epoch 101/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3246 - acc: 0.8792 - val_loss: 1.2486 - val_acc: 0.6786\n",
            "Epoch 102/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3364 - acc: 0.8802 - val_loss: 0.8085 - val_acc: 0.7623\n",
            "Epoch 103/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3180 - acc: 0.8797 - val_loss: 0.9235 - val_acc: 0.7422\n",
            "Epoch 104/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3525 - acc: 0.8698 - val_loss: 1.3122 - val_acc: 0.6908\n",
            "Epoch 105/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3490 - acc: 0.8702 - val_loss: 0.8812 - val_acc: 0.7489\n",
            "Epoch 106/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3463 - acc: 0.8708 - val_loss: 0.8916 - val_acc: 0.7567\n",
            "Epoch 107/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3217 - acc: 0.8820 - val_loss: 0.7739 - val_acc: 0.7600\n",
            "Epoch 108/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3324 - acc: 0.8749 - val_loss: 0.7908 - val_acc: 0.7634\n",
            "Epoch 109/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3247 - acc: 0.8792 - val_loss: 0.8270 - val_acc: 0.7701\n",
            "Epoch 110/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3190 - acc: 0.8852 - val_loss: 0.9996 - val_acc: 0.7344\n",
            "Epoch 111/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3168 - acc: 0.8799 - val_loss: 1.1303 - val_acc: 0.7210\n",
            "Epoch 112/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3277 - acc: 0.8792 - val_loss: 0.9039 - val_acc: 0.7679\n",
            "Epoch 113/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3058 - acc: 0.8802 - val_loss: 0.8867 - val_acc: 0.7545\n",
            "Epoch 114/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.3196 - acc: 0.8765 - val_loss: 0.9216 - val_acc: 0.7522\n",
            "Epoch 115/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3026 - acc: 0.8945 - val_loss: 1.0430 - val_acc: 0.7277\n",
            "Epoch 116/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3004 - acc: 0.8867 - val_loss: 0.8807 - val_acc: 0.7500\n",
            "Epoch 117/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3026 - acc: 0.8886 - val_loss: 0.9676 - val_acc: 0.7388\n",
            "Epoch 118/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2932 - acc: 0.8942 - val_loss: 1.0881 - val_acc: 0.7344\n",
            "Epoch 119/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2941 - acc: 0.8948 - val_loss: 1.0420 - val_acc: 0.7388\n",
            "Epoch 120/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2879 - acc: 0.8932 - val_loss: 0.8721 - val_acc: 0.7679\n",
            "Epoch 121/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2866 - acc: 0.8882 - val_loss: 0.8958 - val_acc: 0.7589\n",
            "Epoch 122/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2917 - acc: 0.8900 - val_loss: 0.9206 - val_acc: 0.7500\n",
            "Epoch 123/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2971 - acc: 0.8900 - val_loss: 0.9653 - val_acc: 0.7645\n",
            "Epoch 124/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3074 - acc: 0.8867 - val_loss: 1.2100 - val_acc: 0.6920\n",
            "Epoch 125/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2918 - acc: 0.8918 - val_loss: 0.8549 - val_acc: 0.7623\n",
            "Epoch 126/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2636 - acc: 0.9047 - val_loss: 0.8474 - val_acc: 0.7600\n",
            "Epoch 127/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.3043 - acc: 0.8846 - val_loss: 1.0140 - val_acc: 0.7254\n",
            "Epoch 128/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3201 - acc: 0.8841 - val_loss: 0.9321 - val_acc: 0.7422\n",
            "Epoch 129/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2750 - acc: 0.8947 - val_loss: 0.8411 - val_acc: 0.7779\n",
            "Epoch 130/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2756 - acc: 0.8987 - val_loss: 0.9272 - val_acc: 0.7489\n",
            "Epoch 131/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.3249 - acc: 0.8827 - val_loss: 1.0416 - val_acc: 0.7377\n",
            "Epoch 132/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2844 - acc: 0.8974 - val_loss: 0.9475 - val_acc: 0.7444\n",
            "Epoch 133/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2743 - acc: 0.8990 - val_loss: 1.0296 - val_acc: 0.7411\n",
            "Epoch 134/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2772 - acc: 0.8965 - val_loss: 0.9174 - val_acc: 0.7467\n",
            "Epoch 135/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2786 - acc: 0.8961 - val_loss: 1.1980 - val_acc: 0.7210\n",
            "Epoch 136/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2705 - acc: 0.8997 - val_loss: 1.1110 - val_acc: 0.7299\n",
            "Epoch 137/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2640 - acc: 0.8970 - val_loss: 1.1106 - val_acc: 0.7299\n",
            "Epoch 138/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2807 - acc: 0.8974 - val_loss: 1.1982 - val_acc: 0.7009\n",
            "Epoch 139/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2627 - acc: 0.9048 - val_loss: 1.0987 - val_acc: 0.7299\n",
            "Epoch 140/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2538 - acc: 0.9029 - val_loss: 1.0689 - val_acc: 0.7310\n",
            "Epoch 141/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2592 - acc: 0.9020 - val_loss: 1.0665 - val_acc: 0.7377\n",
            "Epoch 142/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2698 - acc: 0.8973 - val_loss: 1.1352 - val_acc: 0.7121\n",
            "Epoch 143/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2498 - acc: 0.9076 - val_loss: 1.0814 - val_acc: 0.7400\n",
            "Epoch 144/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2366 - acc: 0.9090 - val_loss: 1.0135 - val_acc: 0.7522\n",
            "Epoch 145/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2549 - acc: 0.9023 - val_loss: 0.9491 - val_acc: 0.7522\n",
            "Epoch 146/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2515 - acc: 0.9019 - val_loss: 0.9585 - val_acc: 0.7712\n",
            "Epoch 147/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2476 - acc: 0.9096 - val_loss: 0.9476 - val_acc: 0.7768\n",
            "Epoch 148/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2464 - acc: 0.9063 - val_loss: 1.1351 - val_acc: 0.7433\n",
            "Epoch 149/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2597 - acc: 0.9022 - val_loss: 0.9351 - val_acc: 0.7545\n",
            "Epoch 150/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2700 - acc: 0.9020 - val_loss: 0.9022 - val_acc: 0.7879\n",
            "Epoch 151/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2611 - acc: 0.9029 - val_loss: 1.0345 - val_acc: 0.7634\n",
            "Epoch 152/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2757 - acc: 0.8961 - val_loss: 1.0214 - val_acc: 0.7511\n",
            "Epoch 153/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2296 - acc: 0.9129 - val_loss: 1.2332 - val_acc: 0.6975\n",
            "Epoch 154/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2550 - acc: 0.9071 - val_loss: 1.0455 - val_acc: 0.7355\n",
            "Epoch 155/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2387 - acc: 0.9174 - val_loss: 0.9335 - val_acc: 0.7746\n",
            "Epoch 156/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2332 - acc: 0.9105 - val_loss: 0.8895 - val_acc: 0.7835\n",
            "Epoch 157/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2395 - acc: 0.9144 - val_loss: 1.0719 - val_acc: 0.7400\n",
            "Epoch 158/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2355 - acc: 0.9130 - val_loss: 1.0958 - val_acc: 0.7243\n",
            "Epoch 159/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2400 - acc: 0.9140 - val_loss: 1.2827 - val_acc: 0.6763\n",
            "Epoch 160/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2203 - acc: 0.9189 - val_loss: 1.5038 - val_acc: 0.6987\n",
            "Epoch 161/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2301 - acc: 0.9135 - val_loss: 0.9196 - val_acc: 0.7667\n",
            "Epoch 162/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2245 - acc: 0.9141 - val_loss: 1.1723 - val_acc: 0.7522\n",
            "Epoch 163/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2283 - acc: 0.9171 - val_loss: 0.9121 - val_acc: 0.7589\n",
            "Epoch 164/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2212 - acc: 0.9175 - val_loss: 0.8973 - val_acc: 0.7812\n",
            "Epoch 165/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2383 - acc: 0.9092 - val_loss: 1.0500 - val_acc: 0.7500\n",
            "Epoch 166/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2619 - acc: 0.9056 - val_loss: 1.1878 - val_acc: 0.7310\n",
            "Epoch 167/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2356 - acc: 0.9176 - val_loss: 0.9145 - val_acc: 0.7835\n",
            "Epoch 168/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2290 - acc: 0.9171 - val_loss: 1.1270 - val_acc: 0.7377\n",
            "Epoch 169/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2378 - acc: 0.9098 - val_loss: 1.0629 - val_acc: 0.7500\n",
            "Epoch 170/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2259 - acc: 0.9180 - val_loss: 0.9270 - val_acc: 0.7623\n",
            "Epoch 171/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2142 - acc: 0.9229 - val_loss: 0.9989 - val_acc: 0.7511\n",
            "Epoch 172/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2209 - acc: 0.9181 - val_loss: 1.1703 - val_acc: 0.7266\n",
            "Epoch 173/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2452 - acc: 0.9143 - val_loss: 0.9527 - val_acc: 0.7801\n",
            "Epoch 174/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2108 - acc: 0.9237 - val_loss: 1.3761 - val_acc: 0.7087\n",
            "Epoch 175/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2373 - acc: 0.9126 - val_loss: 0.9280 - val_acc: 0.7801\n",
            "Epoch 176/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2329 - acc: 0.9131 - val_loss: 0.9841 - val_acc: 0.7511\n",
            "Epoch 177/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2187 - acc: 0.9177 - val_loss: 1.0618 - val_acc: 0.7634\n",
            "Epoch 178/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2220 - acc: 0.9188 - val_loss: 1.3948 - val_acc: 0.6964\n",
            "Epoch 179/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2198 - acc: 0.9220 - val_loss: 1.0422 - val_acc: 0.7489\n",
            "Epoch 180/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.2298 - acc: 0.9180 - val_loss: 1.2099 - val_acc: 0.7310\n",
            "Epoch 181/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1995 - acc: 0.9229 - val_loss: 1.4379 - val_acc: 0.6998\n",
            "Epoch 182/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2086 - acc: 0.9249 - val_loss: 1.0557 - val_acc: 0.7366\n",
            "Epoch 183/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2079 - acc: 0.9198 - val_loss: 1.1673 - val_acc: 0.7355\n",
            "Epoch 184/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2022 - acc: 0.9261 - val_loss: 1.3730 - val_acc: 0.7054\n",
            "Epoch 185/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2119 - acc: 0.9215 - val_loss: 1.1332 - val_acc: 0.7444\n",
            "Epoch 186/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2049 - acc: 0.9234 - val_loss: 1.1701 - val_acc: 0.7511\n",
            "Epoch 187/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2206 - acc: 0.9159 - val_loss: 1.0119 - val_acc: 0.7623\n",
            "Epoch 188/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.1930 - acc: 0.9244 - val_loss: 1.1332 - val_acc: 0.7511\n",
            "Epoch 189/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.1920 - acc: 0.9297 - val_loss: 1.1089 - val_acc: 0.7567\n",
            "Epoch 190/225\n",
            "26/26 [==============================] - 26s 1s/step - loss: 0.2069 - acc: 0.9279 - val_loss: 1.1530 - val_acc: 0.7411\n",
            "Epoch 191/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1917 - acc: 0.9319 - val_loss: 1.0449 - val_acc: 0.7645\n",
            "Epoch 192/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2212 - acc: 0.9173 - val_loss: 1.5339 - val_acc: 0.7199\n",
            "Epoch 193/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2133 - acc: 0.9278 - val_loss: 0.9629 - val_acc: 0.7567\n",
            "Epoch 194/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1852 - acc: 0.9332 - val_loss: 1.0225 - val_acc: 0.7433\n",
            "Epoch 195/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1933 - acc: 0.9311 - val_loss: 0.9690 - val_acc: 0.7801\n",
            "Epoch 196/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2241 - acc: 0.9202 - val_loss: 1.0272 - val_acc: 0.7612\n",
            "Epoch 197/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2031 - acc: 0.9237 - val_loss: 0.9861 - val_acc: 0.7690\n",
            "Epoch 198/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.2210 - acc: 0.9209 - val_loss: 0.9396 - val_acc: 0.7667\n",
            "Epoch 199/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2023 - acc: 0.9306 - val_loss: 0.9794 - val_acc: 0.7489\n",
            "Epoch 200/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1820 - acc: 0.9364 - val_loss: 0.8577 - val_acc: 0.7857\n",
            "Epoch 201/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.1904 - acc: 0.9246 - val_loss: 1.0342 - val_acc: 0.7712\n",
            "Epoch 202/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1851 - acc: 0.9336 - val_loss: 0.9014 - val_acc: 0.7812\n",
            "Epoch 203/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1855 - acc: 0.9306 - val_loss: 1.1641 - val_acc: 0.7299\n",
            "Epoch 204/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2054 - acc: 0.9270 - val_loss: 1.0330 - val_acc: 0.7612\n",
            "Epoch 205/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1924 - acc: 0.9273 - val_loss: 1.2041 - val_acc: 0.7254\n",
            "Epoch 206/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1754 - acc: 0.9350 - val_loss: 1.1161 - val_acc: 0.7489\n",
            "Epoch 207/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1934 - acc: 0.9274 - val_loss: 1.2761 - val_acc: 0.7388\n",
            "Epoch 208/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1872 - acc: 0.9309 - val_loss: 1.0718 - val_acc: 0.7667\n",
            "Epoch 209/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1742 - acc: 0.9352 - val_loss: 1.2081 - val_acc: 0.7444\n",
            "Epoch 210/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1790 - acc: 0.9339 - val_loss: 0.9945 - val_acc: 0.7701\n",
            "Epoch 211/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1585 - acc: 0.9413 - val_loss: 1.2232 - val_acc: 0.7355\n",
            "Epoch 212/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1964 - acc: 0.9292 - val_loss: 1.1497 - val_acc: 0.7522\n",
            "Epoch 213/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1803 - acc: 0.9365 - val_loss: 1.1031 - val_acc: 0.7567\n",
            "Epoch 214/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.1985 - acc: 0.9228 - val_loss: 1.0198 - val_acc: 0.7667\n",
            "Epoch 215/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1979 - acc: 0.9301 - val_loss: 1.3351 - val_acc: 0.7154\n",
            "Epoch 216/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1808 - acc: 0.9346 - val_loss: 1.0600 - val_acc: 0.7600\n",
            "Epoch 217/225\n",
            "26/26 [==============================] - 26s 998ms/step - loss: 0.1832 - acc: 0.9270 - val_loss: 1.1318 - val_acc: 0.7489\n",
            "Epoch 218/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1770 - acc: 0.9342 - val_loss: 1.0229 - val_acc: 0.7612\n",
            "Epoch 219/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1869 - acc: 0.9335 - val_loss: 1.2961 - val_acc: 0.7254\n",
            "Epoch 220/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2062 - acc: 0.9238 - val_loss: 1.1095 - val_acc: 0.7634\n",
            "Epoch 221/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.2028 - acc: 0.9285 - val_loss: 1.2898 - val_acc: 0.7243\n",
            "Epoch 222/225\n",
            "26/26 [==============================] - 26s 1s/step - loss: 0.1856 - acc: 0.9341 - val_loss: 1.1367 - val_acc: 0.7467\n",
            "Epoch 223/225\n",
            "26/26 [==============================] - 27s 1s/step - loss: 0.1850 - acc: 0.9356 - val_loss: 1.1108 - val_acc: 0.7567\n",
            "Epoch 224/225\n",
            "26/26 [==============================] - 28s 1s/step - loss: 0.1799 - acc: 0.9374 - val_loss: 1.1687 - val_acc: 0.7478\n",
            "Epoch 225/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1713 - acc: 0.9354 - val_loss: 0.9094 - val_acc: 0.7746\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f6bcc6154a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "Y3lICKXoKTIp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython import display"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hxM0fwpH1gTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5ab33023-2453-412b-9775-fddfa9c239ad"
      },
      "cell_type": "code",
      "source": [
        "valid_dir = os.path.join(flowerspath, \"validation\")\n",
        "flower_list = sorted(os.listdir(valid_dir))\n",
        "count = 0\n",
        "for flower_type in flower_list:\n",
        "  flowers = os.listdir(os.path.join(valid_dir, flower_type))\n",
        "  for i in range(180):\n",
        "    flower = os.path.join(valid_dir, flower_type, flowers[i])#random.choice(flowers)) \n",
        "    img = Image.open(flower).convert('RGB')\n",
        "    img = img.resize((image_size, image_size), Image.ANTIALIAS)\n",
        "    arr = np.array(img).reshape((1,image_size, image_size, 3))\n",
        "\n",
        "    pred = model.predict(arr*(1./255)).argmax(axis=-1)[0]\n",
        "    #display.display(display.Image(flower))\n",
        "    #print(flower_type + \" predicted as \" + flower_list[pred])\n",
        "    count += (1 if flower_type == flower_list[pred] else 0)\n",
        "print(\"accuracy: \" + str(count*100/(180*len(flower_list))))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy: 80.44444444444444\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}