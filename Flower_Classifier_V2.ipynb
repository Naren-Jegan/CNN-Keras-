{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Flower Classifier.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/Naren-Jegan/Deep-Learning-Keras/blob/master/Flower_Classifier_V2.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "7JehlDIHLpYa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "1f88e41d-77a4-4ef4-ab6e-e055c7b33a76"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth, drive\n",
        "auth.authenticate_user()\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DqpZVzsXLVEY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import math\n",
        "import os\n",
        "from PIL import Image, ImageFilter, ImageOps, ImageMath\n",
        "import random\n",
        "import pickle\n",
        "from time import sleep"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NKI63h3_VtZQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6c10bd7e-702f-4cc1-a382-558b7523fd55"
      },
      "cell_type": "code",
      "source": [
        "# from tf.keras.models import Sequential  # This does not work!\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import InputLayer, Input\n",
        "from tensorflow.python.keras.layers import Reshape, MaxPooling2D, Dropout, BatchNormalization\n",
        "from tensorflow.python.keras.layers import Conv2D, Dense, Flatten\n",
        "from tensorflow.python.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow import test\n",
        "test.gpu_device_name()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "metadata": {
        "id": "CDpwc_CmVtZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eb5be2b0-32d0-4cbf-d50b-be5986a70b7f"
      },
      "cell_type": "code",
      "source": [
        "tf.__version__"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'1.10.1'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "metadata": {
        "id": "EVJ_ESVmxdDg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "flowerspath = os.path.join(\"drive\", \"My Drive\", \"Colab Notebooks\", \"flowers\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDGhQ-1y3DzM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Inputs\n",
        "\n",
        "activation = 'relu' #@param ['relu', 'softplus', 'tanh', 'sigmoid'] {type:\"string\"}\n",
        "learning_rate = 1e-3 #@param {type:\"number\"}\n",
        "dropout = 0.43 #@param {type:\"slider\", min:0.0, max:0.9, step:0.01}\n",
        "n_epochs = 225 #@param {type:\"slider\", min:25, max:500, step:25}\n",
        "batch_size = 128 #@param {type:\"slider\", min:0, max:1024, step:16}\n",
        "num_classes = 5 #@param {type:\"slider\", min:2, max:100, step:1} \n",
        "\n",
        "batch_size = 1 if batch_size == 0 else batch_size\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "uUNq4VOt1VBS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title Data Agumentation\n",
        "image_size = 128 #@param {type:\"slider\", min:32, max:512, step:32}\n",
        "\n",
        "rotation_range = 40 #@param {type:\"slider\", min:0, max:90, step:1}\n",
        "width_shift_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "height_shift_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "shear_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "zoom_range = 0.2 #@param {type:\"slider\", min:0, max:1, step:0.1}\n",
        "horizontal_flip = True #@param {type:\"boolean\"}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MhqXSHZ3hG9u",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "fec4936b-2fcf-4c96-81ef-c7d42a94295e"
      },
      "cell_type": "code",
      "source": [
        "# this is the augmentation configuration we will use for training\n",
        "train_datagen = ImageDataGenerator(\n",
        "        rotation_range=rotation_range,\n",
        "        width_shift_range=width_shift_range,\n",
        "        height_shift_range=height_shift_range,\n",
        "        rescale=1./255,\n",
        "        shear_range=shear_range,\n",
        "        zoom_range=zoom_range,\n",
        "        horizontal_flip=horizontal_flip)\n",
        "\n",
        "# this is the augmentation configuration we will use for testing:\n",
        "# only rescaling\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# this is a generator that will read pictures found in\n",
        "# subfolers of 'data/train', and indefinitely generate\n",
        "# batches of augmented image data\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        os.path.join(flowerspath, 'train'), # this is the target directory\n",
        "        target_size=(image_size, image_size),  # all images will be resized to 150x150\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')  # since we use categorical_crossentropy loss, we need binary labels\n",
        "\n",
        "# this is a similar generator, for validation data\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "        os.path.join(flowerspath, 'validation'),\n",
        "        target_size=(image_size, image_size),\n",
        "        batch_size=batch_size,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 3423 images belonging to 5 classes.\n",
            "Found 900 images belonging to 5 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "SzwK0wtPVtZt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Start construction of the Keras Sequential model.\n",
        "model = Sequential()\n",
        "\n",
        "# First convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(input_shape=(image_size, image_size, 3), kernel_size=3, strides=1, filters=16, padding='same',\n",
        "                 activation=activation, name='layer_conv11'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn11'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling1\"))\n",
        "\n",
        "# Second convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=32, padding='same',\n",
        "                 activation=activation, name='layer_conv21'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn21'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling2\"))\n",
        "\n",
        "# Third convolutional layer with activation, batchnorm and max-pooling.\n",
        "model.add(Conv2D(kernel_size=3, strides=1, filters=64, padding='same',\n",
        "                 activation=activation, name='layer_conv31'))\n",
        "model.add(BatchNormalization(axis = 3, name = 'bn31'))\n",
        "model.add(MaxPooling2D(pool_size=2, strides=2, name=\"max_pooling3\"))\n",
        "\n",
        "# Flatten the 4-rank output of the convolutional layers\n",
        "# to 2-rank that can be input to a fully-connected / dense layer.\n",
        "model.add(Flatten())\n",
        "\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "# First fully-connected / dense layer with activation.\n",
        "model.add(Dense(1024, activation=activation, name = \"dense_1\"))\n",
        "model.add(BatchNormalization(axis = 1, name = 'bn8'))\n",
        "\n",
        "model.add(Dropout(dropout))\n",
        "# First fully-connected / dense layer with activation.\n",
        "model.add(Dense(1024, activation=activation, name = \"dense_2\"))\n",
        "model.add(BatchNormalization(axis = 1, name = 'bn9'))\n",
        "\n",
        "model.add(Dense(num_classes, activation='softmax', name = \"dense_3\"))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VnG3DzENVtZw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from tensorflow.python.keras.optimizers import Adam\n",
        "\n",
        "optimizer = Adam(lr=learning_rate)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "tLtZLFDCVtZx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=optimizer,\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rOrQ3XKbVtZ1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7996
        },
        "outputId": "ac01e116-1ab6-4834-d69f-594acc7fa760"
      },
      "cell_type": "code",
      "source": [
        "model.fit_generator(train_generator, \n",
        "                    steps_per_epoch=3423//batch_size,\n",
        "                    epochs=n_epochs,\n",
        "                    validation_data = validation_generator,\n",
        "                    validation_steps=900//batch_size\n",
        "         )"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/225\n",
            "26/26 [==============================] - 1713s 66s/step - loss: 1.7811 - acc: 0.4431 - val_loss: 4.6533 - val_acc: 0.1987\n",
            "Epoch 2/225\n",
            "26/26 [==============================] - 34s 1s/step - loss: 1.3216 - acc: 0.5350 - val_loss: 6.4793 - val_acc: 0.1987\n",
            "Epoch 3/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 1.1126 - acc: 0.5793 - val_loss: 9.2034 - val_acc: 0.1987\n",
            "Epoch 4/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 1.0255 - acc: 0.6075 - val_loss: 9.9368 - val_acc: 0.1987\n",
            "Epoch 5/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.9536 - acc: 0.6277 - val_loss: 7.8476 - val_acc: 0.1998\n",
            "Epoch 6/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.9225 - acc: 0.6475 - val_loss: 8.8102 - val_acc: 0.1987\n",
            "Epoch 7/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.8840 - acc: 0.6589 - val_loss: 8.1657 - val_acc: 0.2031\n",
            "Epoch 8/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.8569 - acc: 0.6665 - val_loss: 3.9533 - val_acc: 0.2277\n",
            "Epoch 9/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.8190 - acc: 0.6874 - val_loss: 5.4397 - val_acc: 0.2243\n",
            "Epoch 10/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.7947 - acc: 0.6949 - val_loss: 3.3196 - val_acc: 0.2913\n",
            "Epoch 11/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.7567 - acc: 0.7021 - val_loss: 5.0200 - val_acc: 0.2377\n",
            "Epoch 12/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.7697 - acc: 0.7082 - val_loss: 2.8222 - val_acc: 0.3438\n",
            "Epoch 13/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.7364 - acc: 0.7141 - val_loss: 3.0419 - val_acc: 0.3248\n",
            "Epoch 14/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.7225 - acc: 0.7218 - val_loss: 3.0480 - val_acc: 0.3348\n",
            "Epoch 15/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6931 - acc: 0.7300 - val_loss: 2.7922 - val_acc: 0.3583\n",
            "Epoch 16/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.7270 - acc: 0.7215 - val_loss: 1.7918 - val_acc: 0.4263\n",
            "Epoch 17/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6757 - acc: 0.7389 - val_loss: 2.1129 - val_acc: 0.4531\n",
            "Epoch 18/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6622 - acc: 0.7386 - val_loss: 1.7203 - val_acc: 0.4542\n",
            "Epoch 19/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6720 - acc: 0.7428 - val_loss: 1.4123 - val_acc: 0.5223\n",
            "Epoch 20/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6525 - acc: 0.7516 - val_loss: 1.5922 - val_acc: 0.5346\n",
            "Epoch 21/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6660 - acc: 0.7481 - val_loss: 1.3207 - val_acc: 0.5368\n",
            "Epoch 22/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.6380 - acc: 0.7581 - val_loss: 1.0744 - val_acc: 0.6384\n",
            "Epoch 23/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6390 - acc: 0.7566 - val_loss: 1.2073 - val_acc: 0.5614\n",
            "Epoch 24/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6484 - acc: 0.7439 - val_loss: 1.3102 - val_acc: 0.5614\n",
            "Epoch 25/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.6061 - acc: 0.7666 - val_loss: 0.9084 - val_acc: 0.7087\n",
            "Epoch 26/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.6072 - acc: 0.7647 - val_loss: 1.0324 - val_acc: 0.6607\n",
            "Epoch 27/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5919 - acc: 0.7658 - val_loss: 0.9123 - val_acc: 0.6775\n",
            "Epoch 28/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.5865 - acc: 0.7850 - val_loss: 0.9042 - val_acc: 0.7087\n",
            "Epoch 29/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.5746 - acc: 0.7773 - val_loss: 0.7929 - val_acc: 0.7321\n",
            "Epoch 30/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.5619 - acc: 0.7871 - val_loss: 0.9027 - val_acc: 0.6786\n",
            "Epoch 31/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.5237 - acc: 0.8033 - val_loss: 1.1594 - val_acc: 0.6719\n",
            "Epoch 32/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.5522 - acc: 0.7870 - val_loss: 0.8117 - val_acc: 0.7266\n",
            "Epoch 33/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5378 - acc: 0.8000 - val_loss: 0.9326 - val_acc: 0.7065\n",
            "Epoch 34/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5351 - acc: 0.7960 - val_loss: 0.9117 - val_acc: 0.7009\n",
            "Epoch 35/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5101 - acc: 0.8055 - val_loss: 1.0532 - val_acc: 0.7165\n",
            "Epoch 36/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5092 - acc: 0.8035 - val_loss: 0.8893 - val_acc: 0.7377\n",
            "Epoch 37/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5367 - acc: 0.7897 - val_loss: 0.9659 - val_acc: 0.7087\n",
            "Epoch 38/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4828 - acc: 0.8236 - val_loss: 1.0732 - val_acc: 0.6875\n",
            "Epoch 39/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.4811 - acc: 0.8140 - val_loss: 0.7507 - val_acc: 0.7801\n",
            "Epoch 40/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.5037 - acc: 0.8067 - val_loss: 0.8678 - val_acc: 0.7243\n",
            "Epoch 41/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4792 - acc: 0.8194 - val_loss: 1.1556 - val_acc: 0.6306\n",
            "Epoch 42/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.4951 - acc: 0.8061 - val_loss: 1.1546 - val_acc: 0.6562\n",
            "Epoch 43/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.4748 - acc: 0.8290 - val_loss: 0.8002 - val_acc: 0.7422\n",
            "Epoch 44/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4463 - acc: 0.8222 - val_loss: 0.8118 - val_acc: 0.7455\n",
            "Epoch 45/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4787 - acc: 0.8193 - val_loss: 1.0295 - val_acc: 0.6897\n",
            "Epoch 46/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4641 - acc: 0.8181 - val_loss: 1.0929 - val_acc: 0.6942\n",
            "Epoch 47/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4542 - acc: 0.8281 - val_loss: 1.0933 - val_acc: 0.6797\n",
            "Epoch 48/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4346 - acc: 0.8312 - val_loss: 0.9347 - val_acc: 0.7355\n",
            "Epoch 49/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.4454 - acc: 0.8266 - val_loss: 1.0177 - val_acc: 0.7366\n",
            "Epoch 50/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4515 - acc: 0.8257 - val_loss: 1.0043 - val_acc: 0.7154\n",
            "Epoch 51/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4038 - acc: 0.8442 - val_loss: 1.2755 - val_acc: 0.6685\n",
            "Epoch 52/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4437 - acc: 0.8319 - val_loss: 1.0500 - val_acc: 0.7031\n",
            "Epoch 53/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4067 - acc: 0.8475 - val_loss: 0.9417 - val_acc: 0.7411\n",
            "Epoch 54/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4022 - acc: 0.8479 - val_loss: 1.0391 - val_acc: 0.6975\n",
            "Epoch 55/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3955 - acc: 0.8486 - val_loss: 1.0794 - val_acc: 0.6953\n",
            "Epoch 56/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.4027 - acc: 0.8507 - val_loss: 1.4422 - val_acc: 0.6730\n",
            "Epoch 57/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.3964 - acc: 0.8527 - val_loss: 1.0104 - val_acc: 0.7042\n",
            "Epoch 58/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3971 - acc: 0.8512 - val_loss: 0.8958 - val_acc: 0.7511\n",
            "Epoch 59/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.4012 - acc: 0.8448 - val_loss: 1.0319 - val_acc: 0.7388\n",
            "Epoch 60/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3895 - acc: 0.8528 - val_loss: 0.9780 - val_acc: 0.7165\n",
            "Epoch 61/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3723 - acc: 0.8574 - val_loss: 0.9955 - val_acc: 0.7031\n",
            "Epoch 62/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3604 - acc: 0.8597 - val_loss: 0.9227 - val_acc: 0.7478\n",
            "Epoch 63/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3955 - acc: 0.8569 - val_loss: 1.1414 - val_acc: 0.7277\n",
            "Epoch 64/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3777 - acc: 0.8578 - val_loss: 0.9149 - val_acc: 0.7344\n",
            "Epoch 65/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3632 - acc: 0.8636 - val_loss: 1.2064 - val_acc: 0.6864\n",
            "Epoch 66/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3571 - acc: 0.8723 - val_loss: 0.9769 - val_acc: 0.7310\n",
            "Epoch 67/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3435 - acc: 0.8681 - val_loss: 1.0092 - val_acc: 0.6953\n",
            "Epoch 68/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3719 - acc: 0.8585 - val_loss: 0.9970 - val_acc: 0.7277\n",
            "Epoch 69/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3348 - acc: 0.8734 - val_loss: 1.4002 - val_acc: 0.6786\n",
            "Epoch 70/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3419 - acc: 0.8681 - val_loss: 0.9493 - val_acc: 0.7500\n",
            "Epoch 71/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3534 - acc: 0.8714 - val_loss: 1.0323 - val_acc: 0.7422\n",
            "Epoch 72/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3526 - acc: 0.8633 - val_loss: 1.1246 - val_acc: 0.7321\n",
            "Epoch 73/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3600 - acc: 0.8657 - val_loss: 1.2256 - val_acc: 0.6931\n",
            "Epoch 74/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3417 - acc: 0.8758 - val_loss: 1.5445 - val_acc: 0.6496\n",
            "Epoch 75/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3379 - acc: 0.8737 - val_loss: 0.9234 - val_acc: 0.7556\n",
            "Epoch 76/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3351 - acc: 0.8781 - val_loss: 1.2708 - val_acc: 0.6830\n",
            "Epoch 77/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3376 - acc: 0.8744 - val_loss: 1.0529 - val_acc: 0.7210\n",
            "Epoch 78/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3103 - acc: 0.8852 - val_loss: 0.9448 - val_acc: 0.7355\n",
            "Epoch 79/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3130 - acc: 0.8787 - val_loss: 1.1316 - val_acc: 0.7176\n",
            "Epoch 80/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2962 - acc: 0.8946 - val_loss: 1.0347 - val_acc: 0.7199\n",
            "Epoch 81/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3122 - acc: 0.8879 - val_loss: 1.1556 - val_acc: 0.7087\n",
            "Epoch 82/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.3167 - acc: 0.8802 - val_loss: 1.0152 - val_acc: 0.7333\n",
            "Epoch 83/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.3020 - acc: 0.8866 - val_loss: 0.8553 - val_acc: 0.7667\n",
            "Epoch 84/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2944 - acc: 0.8894 - val_loss: 1.0141 - val_acc: 0.7154\n",
            "Epoch 85/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2820 - acc: 0.8944 - val_loss: 1.1758 - val_acc: 0.7109\n",
            "Epoch 86/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3085 - acc: 0.8861 - val_loss: 1.1864 - val_acc: 0.7188\n",
            "Epoch 87/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3004 - acc: 0.8810 - val_loss: 0.9971 - val_acc: 0.7522\n",
            "Epoch 88/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.3030 - acc: 0.8904 - val_loss: 0.9774 - val_acc: 0.7310\n",
            "Epoch 89/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2889 - acc: 0.8903 - val_loss: 0.9471 - val_acc: 0.7511\n",
            "Epoch 90/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2934 - acc: 0.8855 - val_loss: 1.1182 - val_acc: 0.7355\n",
            "Epoch 91/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2787 - acc: 0.8942 - val_loss: 0.9069 - val_acc: 0.7600\n",
            "Epoch 92/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2898 - acc: 0.8921 - val_loss: 1.1443 - val_acc: 0.7076\n",
            "Epoch 93/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2587 - acc: 0.9050 - val_loss: 1.0301 - val_acc: 0.7422\n",
            "Epoch 94/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2816 - acc: 0.8992 - val_loss: 1.1483 - val_acc: 0.7277\n",
            "Epoch 95/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2862 - acc: 0.8944 - val_loss: 1.1076 - val_acc: 0.7467\n",
            "Epoch 96/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2728 - acc: 0.8943 - val_loss: 1.1198 - val_acc: 0.7411\n",
            "Epoch 97/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2845 - acc: 0.8942 - val_loss: 1.2029 - val_acc: 0.7243\n",
            "Epoch 98/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2716 - acc: 0.9047 - val_loss: 1.1236 - val_acc: 0.7254\n",
            "Epoch 99/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2518 - acc: 0.9077 - val_loss: 0.9724 - val_acc: 0.7511\n",
            "Epoch 100/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2688 - acc: 0.9023 - val_loss: 1.0432 - val_acc: 0.7511\n",
            "Epoch 101/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2709 - acc: 0.8969 - val_loss: 1.2871 - val_acc: 0.7087\n",
            "Epoch 102/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2572 - acc: 0.8993 - val_loss: 0.9697 - val_acc: 0.7522\n",
            "Epoch 103/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2428 - acc: 0.9094 - val_loss: 1.0608 - val_acc: 0.7489\n",
            "Epoch 104/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2485 - acc: 0.9030 - val_loss: 1.1464 - val_acc: 0.7243\n",
            "Epoch 105/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2554 - acc: 0.9078 - val_loss: 1.1262 - val_acc: 0.7310\n",
            "Epoch 106/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2588 - acc: 0.9064 - val_loss: 1.1691 - val_acc: 0.7455\n",
            "Epoch 107/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2736 - acc: 0.9004 - val_loss: 1.3111 - val_acc: 0.7098\n",
            "Epoch 108/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2609 - acc: 0.9012 - val_loss: 1.0307 - val_acc: 0.7645\n",
            "Epoch 109/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2485 - acc: 0.9086 - val_loss: 1.0425 - val_acc: 0.7645\n",
            "Epoch 110/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.2495 - acc: 0.9044 - val_loss: 1.1628 - val_acc: 0.7221\n",
            "Epoch 111/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.2508 - acc: 0.9002 - val_loss: 1.1881 - val_acc: 0.7400\n",
            "Epoch 112/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2431 - acc: 0.9135 - val_loss: 0.9803 - val_acc: 0.7589\n",
            "Epoch 113/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2307 - acc: 0.9187 - val_loss: 1.2213 - val_acc: 0.7199\n",
            "Epoch 114/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2417 - acc: 0.9081 - val_loss: 1.0700 - val_acc: 0.7489\n",
            "Epoch 115/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2438 - acc: 0.9101 - val_loss: 0.9798 - val_acc: 0.7455\n",
            "Epoch 116/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2504 - acc: 0.9114 - val_loss: 0.9952 - val_acc: 0.7500\n",
            "Epoch 117/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2593 - acc: 0.9014 - val_loss: 1.0357 - val_acc: 0.7567\n",
            "Epoch 118/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2483 - acc: 0.9130 - val_loss: 1.0844 - val_acc: 0.7545\n",
            "Epoch 119/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2163 - acc: 0.9210 - val_loss: 1.0890 - val_acc: 0.7500\n",
            "Epoch 120/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2106 - acc: 0.9259 - val_loss: 1.1364 - val_acc: 0.7422\n",
            "Epoch 121/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2260 - acc: 0.9133 - val_loss: 1.2815 - val_acc: 0.7143\n",
            "Epoch 122/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2413 - acc: 0.9053 - val_loss: 1.1997 - val_acc: 0.7009\n",
            "Epoch 123/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2205 - acc: 0.9189 - val_loss: 1.5014 - val_acc: 0.6797\n",
            "Epoch 124/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2076 - acc: 0.9246 - val_loss: 1.1117 - val_acc: 0.7500\n",
            "Epoch 125/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2370 - acc: 0.9153 - val_loss: 1.2668 - val_acc: 0.7188\n",
            "Epoch 126/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2249 - acc: 0.9120 - val_loss: 1.5828 - val_acc: 0.6652\n",
            "Epoch 127/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2185 - acc: 0.9237 - val_loss: 1.3850 - val_acc: 0.6931\n",
            "Epoch 128/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2090 - acc: 0.9268 - val_loss: 1.1136 - val_acc: 0.7288\n",
            "Epoch 129/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2129 - acc: 0.9237 - val_loss: 1.2410 - val_acc: 0.7266\n",
            "Epoch 130/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2064 - acc: 0.9261 - val_loss: 1.2988 - val_acc: 0.7321\n",
            "Epoch 131/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2169 - acc: 0.9198 - val_loss: 1.1451 - val_acc: 0.7444\n",
            "Epoch 132/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2050 - acc: 0.9225 - val_loss: 1.2959 - val_acc: 0.7065\n",
            "Epoch 133/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2095 - acc: 0.9257 - val_loss: 1.0390 - val_acc: 0.7567\n",
            "Epoch 134/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2248 - acc: 0.9220 - val_loss: 1.1436 - val_acc: 0.7455\n",
            "Epoch 135/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2072 - acc: 0.9257 - val_loss: 1.1712 - val_acc: 0.7076\n",
            "Epoch 136/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.2084 - acc: 0.9225 - val_loss: 1.1863 - val_acc: 0.7277\n",
            "Epoch 137/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.2125 - acc: 0.9199 - val_loss: 1.1297 - val_acc: 0.7679\n",
            "Epoch 138/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1976 - acc: 0.9283 - val_loss: 1.1625 - val_acc: 0.7478\n",
            "Epoch 139/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1774 - acc: 0.9330 - val_loss: 1.2708 - val_acc: 0.7288\n",
            "Epoch 140/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1909 - acc: 0.9303 - val_loss: 1.2040 - val_acc: 0.7310\n",
            "Epoch 141/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2186 - acc: 0.9279 - val_loss: 1.2625 - val_acc: 0.7366\n",
            "Epoch 142/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2143 - acc: 0.9202 - val_loss: 1.2926 - val_acc: 0.7221\n",
            "Epoch 143/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2131 - acc: 0.9232 - val_loss: 1.2871 - val_acc: 0.7188\n",
            "Epoch 144/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1897 - acc: 0.9336 - val_loss: 1.2715 - val_acc: 0.7266\n",
            "Epoch 145/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2002 - acc: 0.9239 - val_loss: 1.0693 - val_acc: 0.7567\n",
            "Epoch 146/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2105 - acc: 0.9258 - val_loss: 1.1732 - val_acc: 0.7299\n",
            "Epoch 147/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1877 - acc: 0.9308 - val_loss: 1.0633 - val_acc: 0.7433\n",
            "Epoch 148/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1956 - acc: 0.9313 - val_loss: 1.3908 - val_acc: 0.7188\n",
            "Epoch 149/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1729 - acc: 0.9405 - val_loss: 1.1606 - val_acc: 0.7444\n",
            "Epoch 150/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1824 - acc: 0.9291 - val_loss: 1.1571 - val_acc: 0.7500\n",
            "Epoch 151/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.2002 - acc: 0.9287 - val_loss: 1.0405 - val_acc: 0.7556\n",
            "Epoch 152/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1698 - acc: 0.9369 - val_loss: 1.1556 - val_acc: 0.7478\n",
            "Epoch 153/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1969 - acc: 0.9285 - val_loss: 1.3483 - val_acc: 0.7277\n",
            "Epoch 154/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1716 - acc: 0.9371 - val_loss: 1.1673 - val_acc: 0.7545\n",
            "Epoch 155/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1859 - acc: 0.9326 - val_loss: 1.0906 - val_acc: 0.7467\n",
            "Epoch 156/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1945 - acc: 0.9304 - val_loss: 1.1128 - val_acc: 0.7712\n",
            "Epoch 157/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1687 - acc: 0.9367 - val_loss: 1.5694 - val_acc: 0.7042\n",
            "Epoch 158/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1621 - acc: 0.9464 - val_loss: 1.2516 - val_acc: 0.7478\n",
            "Epoch 159/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1770 - acc: 0.9367 - val_loss: 1.7418 - val_acc: 0.6808\n",
            "Epoch 160/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1716 - acc: 0.9383 - val_loss: 1.1594 - val_acc: 0.7433\n",
            "Epoch 161/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1874 - acc: 0.9353 - val_loss: 1.0402 - val_acc: 0.7757\n",
            "Epoch 162/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1570 - acc: 0.9414 - val_loss: 1.2095 - val_acc: 0.7444\n",
            "Epoch 163/225\n",
            "26/26 [==============================] - 29s 1s/step - loss: 0.1589 - acc: 0.9455 - val_loss: 1.3879 - val_acc: 0.7143\n",
            "Epoch 164/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1842 - acc: 0.9315 - val_loss: 1.3932 - val_acc: 0.6953\n",
            "Epoch 165/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1707 - acc: 0.9406 - val_loss: 1.1368 - val_acc: 0.7444\n",
            "Epoch 166/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1500 - acc: 0.9478 - val_loss: 1.3466 - val_acc: 0.7321\n",
            "Epoch 167/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.2016 - acc: 0.9280 - val_loss: 1.5776 - val_acc: 0.6964\n",
            "Epoch 168/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1667 - acc: 0.9353 - val_loss: 1.4038 - val_acc: 0.7210\n",
            "Epoch 169/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1693 - acc: 0.9366 - val_loss: 1.1721 - val_acc: 0.7567\n",
            "Epoch 170/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1699 - acc: 0.9418 - val_loss: 1.1306 - val_acc: 0.7612\n",
            "Epoch 171/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1624 - acc: 0.9446 - val_loss: 1.2472 - val_acc: 0.7478\n",
            "Epoch 172/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1687 - acc: 0.9327 - val_loss: 1.3131 - val_acc: 0.7042\n",
            "Epoch 173/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1654 - acc: 0.9405 - val_loss: 1.2165 - val_acc: 0.7366\n",
            "Epoch 174/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1782 - acc: 0.9348 - val_loss: 1.0526 - val_acc: 0.7612\n",
            "Epoch 175/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1612 - acc: 0.9369 - val_loss: 1.1173 - val_acc: 0.7723\n",
            "Epoch 176/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1730 - acc: 0.9343 - val_loss: 1.1368 - val_acc: 0.7500\n",
            "Epoch 177/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1604 - acc: 0.9399 - val_loss: 1.2964 - val_acc: 0.7266\n",
            "Epoch 178/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1546 - acc: 0.9451 - val_loss: 1.2287 - val_acc: 0.7377\n",
            "Epoch 179/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1628 - acc: 0.9360 - val_loss: 1.1595 - val_acc: 0.7533\n",
            "Epoch 180/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1494 - acc: 0.9450 - val_loss: 1.1261 - val_acc: 0.7578\n",
            "Epoch 181/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1862 - acc: 0.9335 - val_loss: 1.1946 - val_acc: 0.7433\n",
            "Epoch 182/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1562 - acc: 0.9428 - val_loss: 1.1990 - val_acc: 0.7489\n",
            "Epoch 183/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1502 - acc: 0.9492 - val_loss: 1.4568 - val_acc: 0.7210\n",
            "Epoch 184/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1490 - acc: 0.9479 - val_loss: 1.3884 - val_acc: 0.7009\n",
            "Epoch 185/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1310 - acc: 0.9533 - val_loss: 1.1155 - val_acc: 0.7388\n",
            "Epoch 186/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1533 - acc: 0.9482 - val_loss: 1.1254 - val_acc: 0.7600\n",
            "Epoch 187/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1636 - acc: 0.9399 - val_loss: 1.1727 - val_acc: 0.7321\n",
            "Epoch 188/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1465 - acc: 0.9502 - val_loss: 1.1170 - val_acc: 0.7400\n",
            "Epoch 189/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1346 - acc: 0.9543 - val_loss: 1.0853 - val_acc: 0.7533\n",
            "Epoch 190/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1468 - acc: 0.9451 - val_loss: 1.2752 - val_acc: 0.7321\n",
            "Epoch 191/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1376 - acc: 0.9456 - val_loss: 1.2277 - val_acc: 0.7511\n",
            "Epoch 192/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1461 - acc: 0.9480 - val_loss: 1.1906 - val_acc: 0.7422\n",
            "Epoch 193/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1403 - acc: 0.9535 - val_loss: 1.1639 - val_acc: 0.7545\n",
            "Epoch 194/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1435 - acc: 0.9468 - val_loss: 1.2455 - val_acc: 0.7444\n",
            "Epoch 195/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1353 - acc: 0.9496 - val_loss: 1.2888 - val_acc: 0.7433\n",
            "Epoch 196/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1396 - acc: 0.9481 - val_loss: 1.3910 - val_acc: 0.7310\n",
            "Epoch 197/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1476 - acc: 0.9497 - val_loss: 1.2605 - val_acc: 0.7355\n",
            "Epoch 198/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1685 - acc: 0.9461 - val_loss: 1.6433 - val_acc: 0.7143\n",
            "Epoch 199/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1664 - acc: 0.9420 - val_loss: 1.5326 - val_acc: 0.6842\n",
            "Epoch 200/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1514 - acc: 0.9417 - val_loss: 1.4927 - val_acc: 0.7299\n",
            "Epoch 201/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1401 - acc: 0.9475 - val_loss: 1.5026 - val_acc: 0.7109\n",
            "Epoch 202/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1583 - acc: 0.9393 - val_loss: 1.3906 - val_acc: 0.7210\n",
            "Epoch 203/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1454 - acc: 0.9462 - val_loss: 1.4321 - val_acc: 0.7243\n",
            "Epoch 204/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1462 - acc: 0.9456 - val_loss: 1.4462 - val_acc: 0.7121\n",
            "Epoch 205/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1447 - acc: 0.9503 - val_loss: 1.2330 - val_acc: 0.7556\n",
            "Epoch 206/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1407 - acc: 0.9501 - val_loss: 1.2220 - val_acc: 0.7556\n",
            "Epoch 207/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1406 - acc: 0.9515 - val_loss: 1.4596 - val_acc: 0.7232\n",
            "Epoch 208/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1406 - acc: 0.9480 - val_loss: 1.2421 - val_acc: 0.7444\n",
            "Epoch 209/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1329 - acc: 0.9521 - val_loss: 1.3655 - val_acc: 0.7321\n",
            "Epoch 210/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1304 - acc: 0.9562 - val_loss: 1.2144 - val_acc: 0.7634\n",
            "Epoch 211/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1523 - acc: 0.9457 - val_loss: 1.2806 - val_acc: 0.7288\n",
            "Epoch 212/225\n",
            "26/26 [==============================] - 32s 1s/step - loss: 0.1524 - acc: 0.9453 - val_loss: 1.3650 - val_acc: 0.7176\n",
            "Epoch 213/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1479 - acc: 0.9445 - val_loss: 1.5699 - val_acc: 0.6987\n",
            "Epoch 214/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1554 - acc: 0.9467 - val_loss: 1.3034 - val_acc: 0.7254\n",
            "Epoch 215/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1315 - acc: 0.9525 - val_loss: 1.1975 - val_acc: 0.7400\n",
            "Epoch 216/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1409 - acc: 0.9462 - val_loss: 1.6501 - val_acc: 0.7009\n",
            "Epoch 217/225\n",
            "26/26 [==============================] - 30s 1s/step - loss: 0.1529 - acc: 0.9446 - val_loss: 1.4672 - val_acc: 0.7232\n",
            "Epoch 218/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1391 - acc: 0.9494 - val_loss: 1.3062 - val_acc: 0.7589\n",
            "Epoch 219/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1274 - acc: 0.9528 - val_loss: 1.2616 - val_acc: 0.7467\n",
            "Epoch 220/225\n",
            "26/26 [==============================] - 33s 1s/step - loss: 0.1286 - acc: 0.9528 - val_loss: 1.1933 - val_acc: 0.7656\n",
            "Epoch 221/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1344 - acc: 0.9510 - val_loss: 1.3013 - val_acc: 0.7478\n",
            "Epoch 222/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1236 - acc: 0.9585 - val_loss: 1.2131 - val_acc: 0.7578\n",
            "Epoch 223/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1228 - acc: 0.9529 - val_loss: 1.1601 - val_acc: 0.7344\n",
            "Epoch 224/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1430 - acc: 0.9495 - val_loss: 1.1472 - val_acc: 0.7589\n",
            "Epoch 225/225\n",
            "26/26 [==============================] - 31s 1s/step - loss: 0.1355 - acc: 0.9544 - val_loss: 1.2915 - val_acc: 0.7400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f2dd1fae780>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "metadata": {
        "id": "hxM0fwpH1gTc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 477
        },
        "outputId": "0652a2ec-de24-494e-8335-f17fd3d35fe1"
      },
      "cell_type": "code",
      "source": [
        "valid_dir = os.path.join(flowerspath, \"validation\")\n",
        "flower_list = sorted(os.listdir(valid_dir))\n",
        "count = 0\n",
        "for flower_type in flower_list:\n",
        "  flowers = os.listdir(os.path.join(valid_dir, flower_type))\n",
        "  for i in range(5):\n",
        "    flower = os.path.join(valid_dir, flower_type, random.choice(flowers)) \n",
        "    img = Image.open(flower).convert('RGB')\n",
        "    img = img.resize((image_size, image_size), Image.ANTIALIAS)\n",
        "    arr = np.array(img).reshape((1,image_size, image_size, 3))\n",
        "\n",
        "    pred = model.predict(arr*(1./255)).argmax(axis=-1)[0]\n",
        "    print(flower_type + \" predicted as \" + flower_list[pred])\n",
        "    count += (1 if flower_type == flower_list[pred] else 0)\n",
        "print(\"accuracy: \" + str(count*100/(5*len(flower_list))))"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "daisy predicted as daisy\n",
            "daisy predicted as dandelion\n",
            "daisy predicted as daisy\n",
            "daisy predicted as tulip\n",
            "daisy predicted as daisy\n",
            "dandelion predicted as dandelion\n",
            "dandelion predicted as sunflower\n",
            "dandelion predicted as dandelion\n",
            "dandelion predicted as dandelion\n",
            "dandelion predicted as sunflower\n",
            "rose predicted as rose\n",
            "rose predicted as rose\n",
            "rose predicted as rose\n",
            "rose predicted as rose\n",
            "rose predicted as rose\n",
            "sunflower predicted as sunflower\n",
            "sunflower predicted as tulip\n",
            "sunflower predicted as sunflower\n",
            "sunflower predicted as sunflower\n",
            "sunflower predicted as sunflower\n",
            "tulip predicted as tulip\n",
            "tulip predicted as tulip\n",
            "tulip predicted as rose\n",
            "tulip predicted as tulip\n",
            "tulip predicted as tulip\n",
            "accuracy: 76.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}